{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today we are going to perform the simple classification of the amazon reviews' sentiment.\n",
    "\n",
    "### Please, download the dataset amazon_baby.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import html\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    # translator = str.maketrans('', '', string.punctuation)\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    return html.unescape(text).translate(translator)\n",
    "\n",
    "baby_df = pd.read_csv('amazon_baby.csv')\n",
    "baby_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (data preparation)\n",
    "a) Remove punctuation from reviews using the given function.   \n",
    "b) Replace all missing (nan) revies with empty \"\" string.  \n",
    "c) Drop all the entries with rating = 3, as they have neutral sentiment.   \n",
    "d) Set all positive ($\\geq$4) ratings to 1 and negative($\\leq$2) to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "baby_df['review'] = baby_df['review'].apply(lambda x: '' if x != x else x)\n",
    "\n",
    "#short test:\n",
    "baby_df[\"review\"][38] == baby_df[\"review\"][38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "baby_df['review'] = baby_df['review'].apply(remove_punctuation)\n",
    "\n",
    "#short test: \n",
    "baby_df[\"review\"][4] == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'\n",
    "remove_punctuation(baby_df[\"review\"][4]) == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "\n",
    "baby_df.drop(baby_df[baby_df['rating'] == 3].index, inplace = True)\n",
    "\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"] == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d)\n",
    "\n",
    "baby_df['rating'] = baby_df['rating'].apply(lambda x: 1 if x > 3 else -1)\n",
    "\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"]**2 != 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "reviews_train_example = [\"We like apples\",\n",
    "                   \"We hate oranges\",\n",
    "                   \"I adore bananas\",\n",
    "                   \"We like like apples and oranges\",\n",
    "                   \"They dislike bananas\"]\n",
    "\n",
    "X_train_example = vectorizer.fit_transform(reviews_train_example)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X_train_example.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test_example = [\"They like bananas\",\n",
    "                   \"We hate oranges bananas and apples\",\n",
    "                   \"We love bananas\"] #New word!\n",
    "\n",
    "X_test_example = vectorizer.transform(reviews_test_example)\n",
    "\n",
    "print(X_test_example.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "a) Split dataset into training and test sets.     \n",
    "b) Transform reviews into vectors using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "baby_df_train, baby_df_test = train_test_split(baby_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "vectorizer = CountVectorizer(\n",
    "    max_df=0.999,\n",
    "    min_df=5,\n",
    "    max_features=10_000\n",
    ")\n",
    "\n",
    "baby_df_train_vec = vectorizer.fit_transform(baby_df_train['review'])\n",
    "baby_df_test_vec = vectorizer.transform(baby_df_test['review'])\n",
    "\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   \n",
    "b) Print 10 most positive and 10 most negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "model = LogisticRegression(\n",
    "    solver='newton-cg',\n",
    "    multi_class='ovr'\n",
    "    #, class_weight='balanced'\n",
    "    #, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(baby_df_train_vec, baby_df_train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "\n",
    "result = list(zip(*model.coef_, vectorizer.get_feature_names()))\n",
    "result.sort(key = lambda x: x[0])\n",
    "result.reverse()\n",
    "\n",
    "out = '{1:15s} ({0: .3f})'\n",
    "for word in result[:10]:\n",
    "    print(out.format(*word))\n",
    "print('...')\n",
    "for word in result[-10:]:\n",
    "    print(out.format(*word))\n",
    "\n",
    "#hint: model.coef_, vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "a) Predict the sentiment of test data reviews.   \n",
    "b) Predict the sentiment of test data reviews in terms of probability.   \n",
    "c) Find five most positive and most negative reviews.   \n",
    "d) Calculate the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "\n",
    "baby_df_test_prediction = model.predict(baby_df_test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "\n",
    "baby_df_test_prediction_prob = model.predict_proba(baby_df_test_vec)\n",
    "\n",
    "#hint: model.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "\n",
    "tmp = sorted(zip(baby_df_test_prediction_prob, baby_df_test['review']),\n",
    "    key = lambda x: x[0][1]\n",
    ")\n",
    "\n",
    "for i in tmp[-5:]:\n",
    "    print(i[0])\n",
    "    print(i[1][:80])\n",
    "\n",
    "print('...')\n",
    "\n",
    "for i in tmp[:5][::-1]:\n",
    "    print(i[0])\n",
    "    print(i[1][:80])\n",
    "\n",
    "#hint: use the results of b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(baby_df_test['rating'], baby_df_test_prediction).ravel()\n",
    "\n",
    "row_format = '{:>12}' * 3\n",
    "print(row_format.format('', 'Actual -1', 'Actual  1'))\n",
    "print(row_format.format('Pred -1', tn, fn))\n",
    "print(row_format.format('Pred  1', fp, tp))\n",
    "print()\n",
    "\n",
    "# precision: tp / (tp + fp)\n",
    "# recall: tp / (tp + fn) = tp / p\n",
    "\n",
    "print(classification_report(baby_df_test['rating'], baby_df_test_prediction))\n",
    "print(accuracy_score(baby_df_test['rating'], baby_df_test_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
    "\n",
    "\n",
    "a) Redo exercises 2-5 using limited dictionary.   \n",
    "b) Check the impact of all the words from the dictionary.   \n",
    "c) Compare accuracy of predictions and the time of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love','great','easy','old','little','perfect','loves','well','able','car','broke','less','even','waste','disappointed','work','product','money','would','return']\n",
    "len(significant_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "\n",
    "vectorizer_5 = CountVectorizer(\n",
    "    vocabulary = significant_words\n",
    ")\n",
    "\n",
    "baby_df_train_vec_5 = vectorizer_5.fit_transform(baby_df_train['review'])\n",
    "baby_df_test_vec_5 = vectorizer_5.transform(baby_df_test['review'])\n",
    "\n",
    "model_5 = LogisticRegression(\n",
    "    solver='newton-cg',\n",
    "    multi_class='ovr'\n",
    "    #, class_weight='balanced'\n",
    "    #, random_state=42\n",
    ")\n",
    "\n",
    "model_5.fit(baby_df_train_vec_5, baby_df_train['rating'])\n",
    "\n",
    "result_5 = list(zip(*model_5.coef_, vectorizer_5.get_feature_names()))\n",
    "result_5.sort()\n",
    "result_5.reverse()\n",
    "\n",
    "for word in result_5[:10]:\n",
    "    print(out.format(*word))\n",
    "print('...')\n",
    "for word in result_5[-10:]:\n",
    "    print(out.format(*word))\n",
    "\n",
    "print()\n",
    "\n",
    "baby_df_test_prediction_5 = model_5.predict(baby_df_test_vec_5)\n",
    "\n",
    "baby_df_test_prediction_prob_5 = model_5.predict_proba(baby_df_test_vec_5)\n",
    "\n",
    "tmp_5 = sorted(zip(baby_df_test_prediction_prob_5, baby_df_test['review']),\n",
    "    key = lambda x: x[0][1]\n",
    ")\n",
    "\n",
    "for i in tmp_5[-5:]:\n",
    "    print(i[0])\n",
    "    print(i[1][:80])\n",
    "\n",
    "print('...')\n",
    "\n",
    "for i in tmp_5[:5][::-1]:\n",
    "    print(i[0])\n",
    "    print(i[1][:80])\n",
    "\n",
    "print()\n",
    "\n",
    "tn_5, fp_5, fn_5, tp_5 = confusion_matrix(baby_df_test['rating'], baby_df_test_prediction_5).ravel()\n",
    "\n",
    "print(row_format.format('', 'Actual -1', 'Actual  1'))\n",
    "print(row_format.format('Pred -1', tn_5, fn_5))\n",
    "print(row_format.format('Pred  1', fp_5, tp_5))\n",
    "print()\n",
    "\n",
    "print(classification_report(baby_df_test['rating'], baby_df_test_prediction_5))\n",
    "print(accuracy_score(baby_df_test['rating'], baby_df_test_prediction_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "bar = list(zip(*result_5))\n",
    "plt.bar(bar[1], bar[0], zorder = 5)\n",
    "plt.grid(True, axis='x')\n",
    "plt.xticks(rotation=90)\n",
    "plt.gcf().set_size_inches(10,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(baby_df_test['rating'], baby_df_test_prediction).ravel()\n",
    "\n",
    "row_format = '{:>12}' * 3\n",
    "print(row_format.format('', 'Actual -1', 'Actual  1'))\n",
    "print(row_format.format('Pred -1', tn, fn))\n",
    "print(row_format.format('Pred  1', fp, tp))\n",
    "print()\n",
    "\n",
    "print(classification_report(baby_df_test['rating'], baby_df_test_prediction))\n",
    "print(accuracy_score(baby_df_test['rating'], baby_df_test_prediction))\n",
    "\n",
    "print()\n",
    "test1 = CountVectorizer(max_df=0.999, min_df=5, max_features=10_000).fit_transform(baby_df_train['review'])\n",
    "%timeit -r4 LogisticRegression(solver='newton-cg', multi_class='ovr').fit(test1, baby_df_train['rating'])\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "tn_5, fp_5, fn_5, tp_5 = confusion_matrix(baby_df_test['rating'], baby_df_test_prediction_5).ravel()\n",
    "\n",
    "print(row_format.format('', 'Actual -1', 'Actual  1'))\n",
    "print(row_format.format('Pred -1', tn_5, fn_5))\n",
    "print(row_format.format('Pred  1', fp_5, tp_5))\n",
    "print()\n",
    "\n",
    "print(classification_report(baby_df_test['rating'], baby_df_test_prediction_5))\n",
    "print(accuracy_score(baby_df_test['rating'], baby_df_test_prediction_5))\n",
    "\n",
    "print()\n",
    "test2 = CountVectorizer(vocabulary = significant_words).fit(baby_df_train['review'])\n",
    "%timeit -r10 LogisticRegression(solver='newton-cg', multi_class='ovr').fit(test2, baby_df_train['rating'])\n",
    "\n",
    "#hint: %time, %timeit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
